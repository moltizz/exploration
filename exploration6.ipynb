{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exploration6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 프로젝트 6: 멋진 작사가 만들기"
      ],
      "metadata": {
        "id": "d12WOphydTvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**라이브러리 버전 확인하기**"
      ],
      "metadata": {
        "id": "RImM6p0sdnoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "id": "Sr_oGKsLdrrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400e8a57-0003-4c10-d534-68838c3c24c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRjXcq4f1TwG",
        "outputId": "d1368740-0e44-42fa-ee68-fd9670c8254e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 다운로드**"
      ],
      "metadata": {
        "id": "8TS6UshVdzEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/drive/lyricist/models\n",
        "!ln -s ~/data ~/drive/lyricist/data"
      ],
      "metadata": {
        "id": "BkuHIPFR1mLr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 읽어오기**"
      ],
      "metadata": {
        "id": "rySNdj-fd1QA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os, re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "txt_file_path = '/content/drive/MyDrive/aiffel/lyricist/data/lyrics/*'\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "# 여러개의 txt 파일을 모두 읽어서 raw_corpus에 담는다.\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines()\n",
        "        raw_corpus.extend(raw)\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ],
      "metadata": {
        "id": "nltcvIfsd8bP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0229b459-c7df-4bf2-f6ab-5cddb857a394"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 크기: 187088\n",
            "Examples:\n",
            " ['Looking for some education', 'Made my way into the night', 'All that bullshit conversation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, sentence in enumerate(raw_corpus):\n",
        "    if len(sentence) == 0: continue  # 길이가 0인 문장은 건너뛴다.\n",
        "    \n",
        "    if idx > 9: break  # 문장 10개 확인\n",
        "\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCOwruxhS9Wx",
        "outputId": "5e9f7a55-18a2-4629-ef54-9a644c2de1ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for some education\n",
            "Made my way into the night\n",
            "All that bullshit conversation\n",
            "Baby, can't you read the signs? I won't bore you with the details, baby\n",
            "I don't even wanna waste your time\n",
            "Let's just say that maybe\n",
            "You could help me ease my mind\n",
            "I ain't Mr. Right But if you're looking for fast love\n",
            "If that's love in your eyes\n",
            "It's more than enough\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 정체**"
      ],
      "metadata": {
        "id": "9mgA9QU-ekO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2. 특수문자 양쪽에 공백을 넣고\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
        "    sentence = sentence.strip() # 5. 다시 양쪽 공백을 지웁니다\n",
        "    sentence = '<start> ' + sentence + ' <end>' # 6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "_5F05Y2vuXre"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 여기에 정제된 문장을 모은다.\n",
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    # 우리가 원하지 않는 문장은 건너뛴다.\n",
        "    if len(sentence) == 0: continue\n",
        "    if len(sentence.split()) >= 13: continue  # 토큰의 개수 15개 넘어가는 문장 제외(start,end포함)\n",
        "    \n",
        "    # 정제를 하고 담는다.\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "# 정제된 결과를 10개만 확인해보자\n",
        "corpus[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0Lg9JYUKcEp",
        "outputId": "56ba1d02-189d-4b3a-a4bd-957485106712"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> looking for some education <end>',\n",
              " '<start> made my way into the night <end>',\n",
              " '<start> all that bullshit conversation <end>',\n",
              " '<start> i don t even wanna waste your time <end>',\n",
              " '<start> let s just say that maybe <end>',\n",
              " '<start> you could help me ease my mind <end>',\n",
              " '<start> i ain t mr . right but if you re looking for fast love <end>',\n",
              " '<start> if that s love in your eyes <end>',\n",
              " '<start> it s more than enough <end>',\n",
              " '<start> had some bad love <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**평가 데이터셋 분리**"
      ],
      "metadata": {
        "id": "NdNa3UytenOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=12000, \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "metadata": {
        "id": "YNZceNnClo9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7762bc1-0a34-4a5b-861c-121c7565d5e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2 290  28 ...   0   0   0]\n",
            " [  2 223  13 ...   0   0   0]\n",
            " [  2  25  17 ...   0   0   0]\n",
            " ...\n",
            " [  2  22  76 ...   0   0   0]\n",
            " [  2  44  26 ...   0   0   0]\n",
            " [  2  22  76 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f5423c1a750>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor[:3,:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FzBPknJNnXW",
        "outputId": "2cf906bb-d4c1-41bc-ee3c-85f13c3ca11c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2  290   28   96 4536    3    0    0    0    0]\n",
            " [   2  223   13   87  224    6  115    3    0    0]\n",
            " [   2   25   17 1072 2290    3    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s85mpBeuL5rK",
        "outputId": "f15f4d97-c374-442e-a3e2-37ce3f00bb67"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "src_input = tensor[:, :-1]\n",
        "tgt_input = tensor[:,1:]\n",
        "\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input,test_size=0.2)\n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "metadata": {
        "id": "PZUW3_BzeqTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496545a8-63ff-44ca-9eac-08875b70a28c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   2  290   28   96 4536    3    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "[ 290   28   96 4536    3    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "\n",
        "# tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12001개\n",
        "VOCAB_SIZE = tokenizer.num_words + 1\n",
        "\n",
        "# 준비한 데이터 소스로부터 데이터셋을 만든다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder = True)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcMFs39YPGFb",
        "outputId": "5626744f-5142-443f-92ef-6e68455923df"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 32), dtype=tf.int32, name=None), TensorSpec(shape=(256, 32), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**인공지능 만들기**"
      ],
      "metadata": {
        "id": "T33G9mZaewjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "embedding_size = 256\n",
        "hidden_size = 1024\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "GBc40KElROmZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "model(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZMjA6qtSk6O",
        "outputId": "6c222ce8-53f0-42b5-b3a0-f95512e5d1ab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 32, 12001), dtype=float32, numpy=\n",
              "array([[[ 8.36752224e-06, -1.59816063e-05,  1.77276364e-04, ...,\n",
              "          9.05434063e-05,  2.39563000e-04,  2.92930315e-04],\n",
              "        [ 5.42002344e-05,  7.83055366e-05,  5.00587979e-04, ...,\n",
              "          4.63830162e-04,  3.94190225e-04,  3.99739161e-04],\n",
              "        [ 3.44010943e-04,  3.02380853e-04,  3.99545184e-04, ...,\n",
              "          6.49386551e-04,  3.95234325e-04,  4.34430374e-04],\n",
              "        ...,\n",
              "        [-2.90568452e-03, -6.07808412e-04, -1.55156036e-03, ...,\n",
              "         -2.94283032e-03,  4.43194387e-03,  2.48325232e-04],\n",
              "        [-2.92123039e-03, -6.19547849e-04, -1.59434450e-03, ...,\n",
              "         -2.97844573e-03,  4.47222777e-03,  1.86859033e-04],\n",
              "        [-2.92983232e-03, -6.33107265e-04, -1.62824348e-03, ...,\n",
              "         -3.00522242e-03,  4.50121379e-03,  1.25784529e-04]],\n",
              "\n",
              "       [[ 8.36752224e-06, -1.59816063e-05,  1.77276364e-04, ...,\n",
              "          9.05434063e-05,  2.39563000e-04,  2.92930315e-04],\n",
              "        [-3.70222842e-05, -1.83567710e-04,  3.64968204e-04, ...,\n",
              "          6.82609025e-05,  1.89720522e-04,  5.67472074e-04],\n",
              "        [ 1.46006176e-04, -1.78438728e-04,  4.36855276e-04, ...,\n",
              "         -1.00278012e-04,  1.73552995e-04,  8.67899333e-04],\n",
              "        ...,\n",
              "        [-2.90502119e-03, -7.97272136e-04, -1.66266842e-03, ...,\n",
              "         -3.14235571e-03,  4.55630710e-03,  2.17550605e-05],\n",
              "        [-2.90666264e-03, -7.90270977e-04, -1.68395985e-03, ...,\n",
              "         -3.14053334e-03,  4.55575529e-03, -3.68851106e-05],\n",
              "        [-2.90722866e-03, -7.84910517e-04, -1.70047069e-03, ...,\n",
              "         -3.13791935e-03,  4.55249567e-03, -8.89272924e-05]],\n",
              "\n",
              "       [[ 8.36752224e-06, -1.59816063e-05,  1.77276364e-04, ...,\n",
              "          9.05434063e-05,  2.39563000e-04,  2.92930315e-04],\n",
              "        [-1.20330253e-04, -2.33031780e-04,  3.49171314e-04, ...,\n",
              "          9.28137524e-05,  4.99985705e-04,  7.17333867e-04],\n",
              "        [-1.95863904e-04, -4.53061104e-04,  4.70553263e-04, ...,\n",
              "          3.57764122e-07,  7.26767583e-04,  1.06741174e-03],\n",
              "        ...,\n",
              "        [-2.93398346e-03, -7.82245654e-04, -1.72902772e-03, ...,\n",
              "         -3.07394471e-03,  4.54745116e-03, -1.92872438e-04],\n",
              "        [-2.93004722e-03, -7.79160822e-04, -1.73347048e-03, ...,\n",
              "         -3.08021856e-03,  4.54009091e-03, -2.24687305e-04],\n",
              "        [-2.92685372e-03, -7.76272675e-04, -1.73681835e-03, ...,\n",
              "         -3.08537716e-03,  4.53225896e-03, -2.52233760e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 8.36752224e-06, -1.59816063e-05,  1.77276364e-04, ...,\n",
              "          9.05434063e-05,  2.39563000e-04,  2.92930315e-04],\n",
              "        [ 1.21015277e-04,  5.68273972e-05,  1.97039801e-04, ...,\n",
              "          2.07922450e-04,  1.36962815e-04,  3.66215419e-04],\n",
              "        [ 4.06687526e-04, -1.31003053e-05,  2.49146047e-04, ...,\n",
              "          9.52734117e-05,  9.36793640e-06,  3.66442255e-04],\n",
              "        ...,\n",
              "        [-2.85458844e-03, -6.52887567e-04, -1.73020642e-03, ...,\n",
              "         -2.98418244e-03,  4.46820725e-03,  4.31113876e-05],\n",
              "        [-2.86458945e-03, -6.70873618e-04, -1.74150034e-03, ...,\n",
              "         -3.00363242e-03,  4.47735330e-03, -1.51966915e-05],\n",
              "        [-2.87232199e-03, -6.86245679e-04, -1.74932426e-03, ...,\n",
              "         -3.01968353e-03,  4.48297523e-03, -6.74454204e-05]],\n",
              "\n",
              "       [[ 8.36752224e-06, -1.59816063e-05,  1.77276364e-04, ...,\n",
              "          9.05434063e-05,  2.39563000e-04,  2.92930315e-04],\n",
              "        [ 1.68851882e-04, -1.83374766e-04,  3.66861379e-04, ...,\n",
              "          2.14109328e-04,  4.92393214e-04,  5.55719773e-04],\n",
              "        [ 3.68881214e-04, -1.70122847e-04,  3.65211774e-04, ...,\n",
              "          2.91609787e-04,  3.93466296e-04,  5.62562258e-04],\n",
              "        ...,\n",
              "        [-2.93671875e-03, -7.67491350e-04, -1.67578261e-03, ...,\n",
              "         -3.07646743e-03,  4.59302682e-03, -1.28275351e-04],\n",
              "        [-2.93399999e-03, -7.66740413e-04, -1.69036759e-03, ...,\n",
              "         -3.08104791e-03,  4.58383793e-03, -1.64539975e-04],\n",
              "        [-2.93120206e-03, -7.66228302e-04, -1.70204381e-03, ...,\n",
              "         -3.08450847e-03,  4.57366044e-03, -1.97013680e-04]],\n",
              "\n",
              "       [[ 8.36752224e-06, -1.59816063e-05,  1.77276364e-04, ...,\n",
              "          9.05434063e-05,  2.39563000e-04,  2.92930315e-04],\n",
              "        [ 2.36912994e-04, -3.08952702e-04,  2.08088430e-04, ...,\n",
              "          1.34126560e-04,  3.21703992e-04,  3.11847893e-04],\n",
              "        [ 4.25006787e-04, -3.83423001e-04,  1.55495130e-04, ...,\n",
              "          2.02197349e-04,  1.24963160e-04,  2.27395591e-04],\n",
              "        ...,\n",
              "        [-2.88022473e-03, -7.71165069e-04, -1.73499889e-03, ...,\n",
              "         -3.09520843e-03,  4.51797713e-03, -1.62681245e-04],\n",
              "        [-2.88361078e-03, -7.72014784e-04, -1.74045179e-03, ...,\n",
              "         -3.09858471e-03,  4.51349560e-03, -1.98344002e-04],\n",
              "        [-2.88686296e-03, -7.72284868e-04, -1.74418697e-03, ...,\n",
              "         -3.10107996e-03,  4.50839894e-03, -2.29324636e-04]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4MWefO5Stc2",
        "outputId": "f1538931-3af2-4ed4-be6a-da099a6c09e7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  3072256   \n",
            "                                                                 \n",
            " lstm (LSTM)                 multiple                  5246976   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               multiple                  8392704   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  12301025  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,012,961\n",
            "Trainable params: 29,012,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "history = model.fit(enc_train,dec_train, validation_data=(enc_val, dec_val), epochs = 10, batch_size = 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HY9vyKvSwvB",
        "outputId": "f67cd89c-eca3-47ac-8956-8cfe6e4829a7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "255/255 [==============================] - 108s 399ms/step - loss: 0.8751 - val_loss: 0.9061\n",
            "Epoch 2/10\n",
            "255/255 [==============================] - 101s 397ms/step - loss: 0.8380 - val_loss: 0.9157\n",
            "Epoch 3/10\n",
            "255/255 [==============================] - 103s 404ms/step - loss: 0.8162 - val_loss: 0.9210\n",
            "Epoch 4/10\n",
            "255/255 [==============================] - 103s 404ms/step - loss: 0.7965 - val_loss: 0.9280\n",
            "Epoch 5/10\n",
            "255/255 [==============================] - 101s 398ms/step - loss: 0.7779 - val_loss: 0.9314\n",
            "Epoch 6/10\n",
            "255/255 [==============================] - 101s 397ms/step - loss: 0.7599 - val_loss: 0.9365\n",
            "Epoch 7/10\n",
            "255/255 [==============================] - 103s 404ms/step - loss: 0.7424 - val_loss: 0.9396\n",
            "Epoch 8/10\n",
            "255/255 [==============================] - 103s 404ms/step - loss: 0.7255 - val_loss: 0.9417\n",
            "Epoch 9/10\n",
            "255/255 [==============================] - 103s 404ms/step - loss: 0.7092 - val_loss: 0.9465\n",
            "Epoch 10/10\n",
            "255/255 [==============================] - 101s 398ms/step - loss: 0.6935 - val_loss: 0.9515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
        "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환한다.\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    while True:\n",
        "        predict = model(test_tensor)  # 1. 입력받은 문장의 텐서를 입력한다.\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1),axis=-1)[:,-1]   # 2. 예측된 값 중 가장 높은 확률인 word index를 뽑아낸다.\n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)   # 3. 2에서 예측된 word index를 문장 뒤에 붙인다.\n",
        "        if predict_word.numpy()[0] == end_token: break   # 4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마친다.\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    for word_index in test_tensor[0].numpy():  # tokenizer를 이용해 word index를 단어로 하나씩 변환한다. \n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "    \n",
        "    return generated"
      ],
      "metadata": {
        "id": "QpLa8PloYehI"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits = True, reduction='none')"
      ],
      "metadata": {
        "id": "8xOMo87Cez08"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7oMPHUmJtpZL",
        "outputId": "2c488a67-4f44-4918-ba20-32f0403a19ff"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i love you , i m not gonna crack <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "난 널 사랑해, 난 깨지지 않을 거야"
      ],
      "metadata": {
        "id": "gmfBgU7Hx0zv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**✍ 회고**"
      ],
      "metadata": {
        "id": "_UM13C-6wxbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Loss는 모델이 오답을 만들고 있는 정도라고 생각하면 된다. 출력된 loss를 보면, 매우 준수하게 오답을 만들고 있다고 판단이 된다. 해당 프로젝트에서 val_loss 값을 2.2 수준으로 줄이라고 했는데, 출력된 val_loss가 대체적으로 1을 넘지 않았다. 추가로 val_loss는 검증데이터에 대한 손실을 나타낸다."
      ],
      "metadata": {
        "id": "vchNAf2Iw36r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 모델이 출력한 가사는 i love you , i m not gonna crack였다. 의미는 '난 널 사랑해, 난 깨지지 않을 거야'이다. 신기한 멘트를 알아서 출력하는 게 재밌다. 배우면 배울수록 신기하고 새롭다..."
      ],
      "metadata": {
        "id": "WxvIVczBzTDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* val_loss를 출력하기 위해 history = model.fit(enc_train,dec_train, validation_data=(enc_val, dec_val), epochs = 10, batch_size = 500) 을 추가해줬다. 적당히 순조로웠다."
      ],
      "metadata": {
        "id": "dwVfkuLUzxUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* epoch를 10번 돌리는데 시간이 좀 걸렸다. 기다리는 재미도 있고, 값 나오는 재미도 있고, 넘 즐거웠다...!"
      ],
      "metadata": {
        "id": "B1cR8o44z84m"
      }
    }
  ]
}